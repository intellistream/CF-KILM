{
    "input_length": 150,
    "output_length": 10,
    "num_train_epochs": 1,
    "split_num": 2,
    "split": 2,
    "output_dir": "",
    "dataset": "newlama_easy",
    "dataset_version": "small",
    "output_log": "log/newlama_easy2/lora.csv",
    "train_batch_size": 32,
    "eval_batch_size": 32,
    "learning_rate": 1e-3,
    "model": "google/t5-large-ssm",
    "method": "lora",
    "freeze_level": 0,
    "gradient_accumulation_steps": 3,
    "ngpu": 2,
    "resume_from_checkpoint": null,
    "accelerator": "ddp",
    "use_deepspeed": false,
    "mode": "pretrain",
    "use_lr_scheduling": false,
    "check_validation": true,
    "checkpoint_path": "outputs/T5_large_recentnews(full)_lora_online"
}